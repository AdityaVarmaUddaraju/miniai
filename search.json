[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "02_meanshift.html",
    "href": "02_meanshift.html",
    "title": "GPU batched algorithm",
    "section": "",
    "text": "import math, matplotlib.pyplot as plt, operator, torch\nfrom functools import partial\n\n\n\ntorch.manual_seed(42)\ntorch.set_printoptions(precision=3, linewidth=140, sci_mode=False)\n\n\nn_clusters = 6\nn_samples = 250\n\n\ncentroids = torch.rand(n_clusters, 2)*70-35\n\n\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch import tensor\n\n\ndef sample(m): return MultivariateNormal(m, torch.diag(tensor([5.,5.]))).sample((n_samples,))\n\n\nslices = [sample(c) for c in centroids]\ndata = torch.cat(slices)\ndata.shape\n\ntorch.Size([1500, 2])\n\n\n\ndef plot_data(centroids, data, n_samples, ax=None):\n    if ax is None: _,ax = plt.subplots()\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples:(i+1)*n_samples]\n        ax.scatter(samples[:,0], samples[:,1], s=1)\n        ax.plot(*centroid, markersize=10, marker=\"x\", color='k', mew=5)\n        ax.plot(*centroid, markersize=5, marker=\"x\", color='m', mew=2)\n\n\nplot_data(centroids, data, n_samples)\n\n\n\n\n\nmidp = data.mean(0)\nmidp\n\ntensor([ 9.222, 11.604])\n\n\n\nplot_data([midp]*6, data, n_samples)\n\n\n\n\n\ndef gaussian(d, bw): return torch.exp(-0.5*((d/bw))**2) / (bw*math.sqrt(2*math.pi))\n\n\ndef plot_function(f):\n    x = torch.linspace(0,10,100)\n    plt.plot(f(x))\n\n\nplot_function(partial(gaussian,bw=2.5))\n\n\n\n\n\nX = data.clone()\nx = X[0]\nx.shape\n\ntorch.Size([2])\n\n\n\n((x-X)**2).sum(1).sqrt()\n\ntensor([ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617])\n\n\n\ndist = ((x-X)**2).sum(1).sqrt()\n\n\nweights = gaussian(dist, 2.5)\nweights.shape\n\ntorch.Size([1500])\n\n\n\nweights.shape, X.shape\n\n(torch.Size([1500]), torch.Size([1500, 2]))\n\n\n\n(weights[:,None] * X).sum(0)\n\ntensor([406.866, 431.454])\n\n\n\nweights.sum()\n\ntensor(15.388)\n\n\n\n((weights[:,None] * X).sum(0))/weights.sum()\n\ntensor([26.440, 28.038])\n\n\n\ndef one_update(X):\n    for i, x in enumerate(X):\n        dist = ((x-X)**2).sum(1).sqrt()\n        weights = gaussian(dist, 2.5)\n        X[i] = ((weights[:,None] * X).sum(0))/weights.sum()\n\n\ndef meanshift(data):\n    X = data.clone()\n    for i in range(5): one_update(X)\n    return X\n\n\n\n\nCPU times: user 1.28 s, sys: 0 ns, total: 1.28 s\nWall time: 1.28 s\n\n\n\nplot_data(centroids+2, data, n_samples)\n\n\n\n\n\nplot_data(centroids+2, X, n_samples)\n\n\n\n\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\ndef do_one(d):\n    if d: one_update(X)\n    ax.clear()\n    plot_data(centroids+2, X, n_samples, ax=ax)\n\n\nX = data.clone()\nfig,ax = plt.subplots()\nani = FuncAnimation(fig, do_one, frames=5, interval=500, repeat=False)\nplt.close()\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nbs = 5\nX = data.clone()\nx = X[:bs]\nX.shape, x.shape\n\n(torch.Size([1500, 2]), torch.Size([5, 2]))\n\n\n\nX[None].shape, x[:,None].shape\n\n(torch.Size([1, 1500, 2]), torch.Size([5, 1, 2]))\n\n\n\n(X[None]-x[:,None]).shape\n\ntorch.Size([5, 1500, 2])\n\n\n\n((X[None]-x[:,None])**2).sum(2).sqrt().shape\n\ntorch.Size([5, 1500])\n\n\n\ndef dist_b(a,b):\n    return ((a[None]-b[:,None])**2).sum(2).sqrt()\n\n\ndist_b(X,x)\n\ntensor([[ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617],\n        [ 3.899,  0.000,  4.978,  ..., 21.499, 26.508, 25.500],\n        [ 4.834,  4.978,  0.000,  ..., 19.373, 24.757, 23.396],\n        [ 3.726,  0.185,  4.969,  ..., 21.335, 26.336, 25.333],\n        [ 6.273,  5.547,  1.615,  ..., 20.775, 26.201, 24.785]])\n\n\n\nweights = gaussian(dist_b(X,x), 2.5)\nweights.shape\n\ntorch.Size([5, 1500])\n\n\n\nX.shape, weights.shape\n\n(torch.Size([1500, 2]), torch.Size([5, 1500]))\n\n\n\n(weights @ X).shape\n\ntorch.Size([5, 2])\n\n\n\ndiv = weights.sum(1, keepdim=True); div.shape\n\ntorch.Size([5, 1])\n\n\n\n(weights@X/div).shape\n\ntorch.Size([5, 2])\n\n\n\ndef meanshift(data, bs=500):\n    X = data.clone()\n    n = len(data)\n    for it in range(5):\n        for i in range(0,n,bs):\n            s = slice(i, min(i+bs, n))\n            dists = dist_b(X, X[s])\n            weights = gaussian(dists, 2.5)\n            div = weights.sum(1, keepdim=True)\n            X[s] = (weights @ X)/div\n    return X\n\n\nif torch.cuda.is_available():\n    data = data.cuda()\n\n\nX = meanshift(data).cpu()\n\n\n\n\nCPU times: user 8.23 ms, sys: 71 µs, total: 8.3 ms\nWall time: 7.24 ms\n\n\n\nplot_data(centroids+2, X, n_samples)\n\n\n\n\n\ntorch.cuda.is_available()\n\nTrue\n\n\n\na = tensor([1])\na.device\n\ndevice(type='cpu')"
  },
  {
    "objectID": "matmul.html",
    "href": "matmul.html",
    "title": "Matrix multiplication from foundations",
    "section": "",
    "text": "from pathlib import Path\nimport pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt\nMNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\npath_data = Path('data')\npath_data.mkdir(exist_ok=True)\npath_gz = path_data/'mnist.pkl.gz'\nfrom urllib.request import urlretrieve\nif not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)\n!ls -l data\n\ntotal 33312\n-rw-r--r--  1 aditya  staff  17051982 Oct 26 12:49 mnist.pkl.gz\nwith gzip.open(path_gz, 'rb') as f:\n    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin')\nlst1 = list(x_train[0])\nvals = lst1[200:210]\nvals\n\n[0.0,\n 0.0,\n 0.0,\n 0.19140625,\n 0.9296875,\n 0.98828125,\n 0.98828125,\n 0.98828125,\n 0.98828125,\n 0.98828125]\ndef chunks(lst, sz):\n    for i in range(0, len(lst), sz):\n        yield lst[i:i+sz]\nlist(chunks(vals, 5))\n\n[[0.0, 0.0, 0.0, 0.19140625, 0.9296875],\n [0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125]]\nmpl.rcParams['image.cmap'] = 'gray'\nplt.imshow(list(chunks(lst1, 28)))\n\n&lt;matplotlib.image.AxesImage&gt;\nfrom itertools import islice\nval_iter = iter(vals)\nlist(islice(val_iter, 5))\n\n[0.0, 0.0, 0.0, 0.19140625, 0.9296875]\nlist(islice(val_iter, 5))\n\n[0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125]\nlist(islice(val_iter, 5))\n\n[]\nit = iter(lst1)\nimg = list(iter(lambda: list(islice(it, 28)), []))\nplt.imshow(img)\n\n&lt;matplotlib.image.AxesImage&gt;\nimg[20][15]\n\n0.98828125\nclass Matrix:\n    def __init__(self,x): self.x = x\n    def __getitem__(self, idxs): return self.x[idxs[0]][idxs[1]]\nm = Matrix(img)\nm[20,15]\n\n0.98828125\nimport torch\nfrom torch import tensor\ntensor([1,2,3])\n\ntensor([1, 2, 3])\nx_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\nx_train.shape\n\ntorch.Size([50000, 784])\nx_train.type()\n\n'torch.FloatTensor'\nimgs = x_train.reshape((-1, 28, 28))\nplt.imshow(imgs[0])\n\n&lt;matplotlib.image.AxesImage&gt;\nimgs[0, 20, 15]\n\ntensor(0.9883)\nn,c = x_train.shape\ny_train, y_train.shape\n\n(tensor([5, 0, 4,  ..., 8, 4, 8]), torch.Size([50000]))\nmin(y_train), max(y_train)\n\n(tensor(0), tensor(9))\ny_train.min(), y_train.max()\n\n(tensor(0), tensor(9))"
  },
  {
    "objectID": "matmul.html#random-numbers",
    "href": "matmul.html#random-numbers",
    "title": "Matrix multiplication from foundations",
    "section": "Random Numbers",
    "text": "Random Numbers\n\nrnd_state = None\ndef seed(a):\n    global rnd_state\n    a, x = divmod(a, 30268)\n    a, y = divmod(a, 30306)\n    a, z = divmod(a, 30322)\n    rnd_state = int(x)+1, int(y)+1, int(z)+1\n\n\nseed(457428938475)\nrnd_state\n\n(4976, 20238, 499)\n\n\n\ndef rand():\n    global rnd_state\n    x, y, z = rnd_state\n    x = (171 * x) % 30269\n    y = (172 * y) % 30307\n    z = (170 * z) % 30323\n    rnd_state = x,y,z\n    return (x/30269 + y/30307 + z/30323) % 1.0\n\n\nrand(), rand(), rand()\n\n(0.7645251082582081, 0.7920889799553945, 0.06912886811267205)\n\n\n\nif os.fork(): print(f'In parent: {rand()}')\nelse:\n    print(f'In child: {rand()}')\n    os._exit(os.EX_OK)\n\nIn parent: 0.9559050644103264\nIn child: 0.9559050644103264\n\n\n\nif os.fork(): print(f'In parent: {torch.rand(1)}')\nelse:\n    print(f'In child: {torch.rand(1)}')\n    os._exit(os.EX_OK)\n\nIn parent: tensor([0.3511])\nIn child: tensor([0.3511])\n\n\n\nplt.plot([rand() for _ in range(50)])\n\n\n\n\n\nplt.hist([rand() for _ in range(10000)])\n\n(array([ 959.,  972., 1036., 1019., 1037.,  971.,  997., 1000., 1036.,\n         973.]),\n array([6.60514437e-06, 1.00005135e-01, 2.00003666e-01, 3.00002196e-01,\n        4.00000726e-01, 4.99999256e-01, 5.99997787e-01, 6.99996317e-01,\n        7.99994847e-01, 8.99993378e-01, 9.99991908e-01]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\n\n\n5.13 ms ± 355 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n\n\n236 µs ± 113 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "matmul.html#matrix-multiplication",
    "href": "matmul.html#matrix-multiplication",
    "title": "Matrix multiplication from foundations",
    "section": "Matrix multiplication",
    "text": "Matrix multiplication\n\nweights = torch.randn(784, 10)\nbias = torch.zeros(10)\n\n\nm1 = x_valid[:5]\nm2 = weights\n\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nar, ac = m1.shape\nbr, bc = m2.shape\n(ar,ac),(br,bc)\n\n((5, 784), (784, 10))\n\n\n\nt1 = torch.zeros((ar, bc))\nt1.shape\n\ntorch.Size([5, 10])\n\n\n\nfor i in range(ar):\n    for j in range(bc):\n        for k in range(ac):\n            t1[i,j] += m1[i,k] * m2[k,j]\n\n\nt1\n\ntensor([[ 12.9630, -10.3799, -16.5003,  11.8395,   8.5769, -13.1003,  -3.8864,\n          -2.5619,  -4.2900,  -1.9307],\n        [  7.0750,  -6.2932,   7.1758,   3.0945,   6.4060,   1.7423,  -2.6365,\n          10.3673,  -1.5848,  -1.3050],\n        [  2.2249,   1.2585,   1.2338,   5.4787,  11.0996,  -5.3456,   2.1196,\n          15.0352,   0.4401,  -5.8730],\n        [  3.8055,   7.7315,  -7.6018,  -3.8148,  15.5802, -15.5535,   3.7193,\n          -2.5585,  -3.0343,   3.4738],\n        [  9.0198,   2.2140,  -4.6859,   5.8690,   0.1192,   0.5790, -13.7248,\n          10.8067,   1.8075,  -2.7698]])\n\n\n\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n\n\nt1\n\ntensor([[ 12.96, -10.38, -16.50,  11.84,   8.58, -13.10,  -3.89,  -2.56,  -4.29,  -1.93],\n        [  7.08,  -6.29,   7.18,   3.09,   6.41,   1.74,  -2.64,  10.37,  -1.58,  -1.30],\n        [  2.22,   1.26,   1.23,   5.48,  11.10,  -5.35,   2.12,  15.04,   0.44,  -5.87],\n        [  3.81,   7.73,  -7.60,  -3.81,  15.58, -15.55,   3.72,  -2.56,  -3.03,   3.47],\n        [  9.02,   2.21,  -4.69,   5.87,   0.12,   0.58, -13.72,  10.81,   1.81,  -2.77]])\n\n\n\nimport numpy as np\n\n\nnp.set_printoptions(precision=2,linewidth=140)\n\n\n(ar,ac),(br,bc) = m1.shape,m2.shape\n(ar,ac),(br,bc)\n\n((5, 784), (784, 10))\n\n\n\ndef matmul(m1,m2):\n    (ar,ac),(br,bc) = m1.shape,m2.shape\n    c = torch.zeros((ar,bc))\n    for i in range(ar):\n        for j in range(bc):\n            for k in range(ac):\n                c[i,j] += m1[i,k] * m2[k,j]\n    return c\n\n\n\n\nCPU times: user 779 ms, sys: 7.65 ms, total: 787 ms\nWall time: 814 ms"
  },
  {
    "objectID": "matmul.html#elementwise-operations",
    "href": "matmul.html#elementwise-operations",
    "title": "Matrix multiplication from foundations",
    "section": "Elementwise operations",
    "text": "Elementwise operations\n\nm1.shape, m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\n(m1[0,:] * m2[:,0]).sum()\n\ntensor(12.96)\n\n\n\ndef matmul(m1,m2):\n    (ar,ac),(br,bc) = m1.shape,m2.shape\n    c = torch.zeros((ar,bc))\n    for i in range(ar):\n        for j in range(bc):\n            c[i,j] = (m1[i,:] * m2[:, j]).sum()\n    return c\n\n\n\n\nCPU times: user 3.83 ms, sys: 3.95 ms, total: 7.78 ms\nWall time: 9.05 ms\n\n\n\nfrom fastcore.test import *\n\n\ntest_close(t1,matmul(m1,m2))\n\n\ndef matmul(m1,m2):\n    (ar,ac),(br,bc) = m1.shape,m2.shape\n    c = torch.zeros((ar,bc))\n    for i in range(ar):\n        for j in range(bc):\n            c[i,j] = torch.dot(m1[i,:], m2[:, j])\n    return c\n\n\n\n\n813 µs ± 89.7 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\ntest_close(t1,matmul(m1,m2))"
  },
  {
    "objectID": "matmul.html#broadcasting",
    "href": "matmul.html#broadcasting",
    "title": "Matrix multiplication from foundations",
    "section": "Broadcasting",
    "text": "Broadcasting\n\nm = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\nc = tensor([10.,20,30]); c\n\ntensor([10., 20., 30.])\n\n\n\nm.shape, c.shape\n\n(torch.Size([3, 3]), torch.Size([3]))\n\n\n\nm+c\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nc + m\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nc.unsqueeze(0), c[None, :]\n\n(tensor([[10., 20., 30.]]), tensor([[10., 20., 30.]]))\n\n\n\nm.shape, c[:,None].shape\n\n(torch.Size([3, 3]), torch.Size([3, 1]))\n\n\n\nc[:,None].expand_as(m)\n\ntensor([[10., 10., 10.],\n        [20., 20., 20.],\n        [30., 30., 30.]])\n\n\n\nm + c[:,None]\n\ntensor([[11., 12., 13.],\n        [24., 25., 26.],\n        [37., 38., 39.]])\n\n\n\nmatmul with broadcasting\n\ndigit = m1[0]\ndigit.shape, m2.shape\n\n(torch.Size([784]), torch.Size([784, 10]))\n\n\n\n(digit[:,None] * m2).sum(dim=0).shape\n\ntorch.Size([10])\n\n\n\ndigits = m1[:2]\n\n\ndigits.shape\n\ntorch.Size([2, 784])\n\n\n\ndigits.shape, m2.shape\n\n(torch.Size([2, 784]), torch.Size([784, 10]))\n\n\n\ndigits[..., None].shape\n\ntorch.Size([2, 784, 1])\n\n\n\n(digits[..., None] * m2).shape\n\ntorch.Size([2, 784, 10])\n\n\n\n(digits[..., None] * m2).sum(dim=1).shape\n\ntorch.Size([2, 10])\n\n\n\ndef matmul(m1,m2):\n    (ar,ac),(br,bc) = m1.shape,m2.shape\n    c = torch.zeros((ar,bc))\n    for i in range(ar):\n            c[i] = (m1[i,:,None] * m2).sum(dim=0)\n    return c\n\n\ntest_close(t1, matmul(m1,m2))\n\n\n\n\nThe slowest run took 4.91 times longer than the fastest. This could mean that an intermediate result is being cached.\n306 µs ± 198 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\ntr = matmul(x_train, weights)\n\n\ntr.shape\n\ntorch.Size([50000, 10])\n\n\n\n\n\nCPU times: user 1.75 s, sys: 23.5 ms, total: 1.77 s\nWall time: 1.52 s"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "miniai",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "miniai",
    "section": "Install",
    "text": "Install\npip install miniai"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "miniai",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  }
]